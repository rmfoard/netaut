%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This file was derived from:
% Journal Article
% LaTeX Template
% Version 1.4 (15/5/16)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com) with extensive modifications by
% Vel (vel@LaTeXTemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[twoside,twocolumn]{article}

\usepackage{blindtext} % Package to generate dummy text throughout this template 

\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

\usepackage[english]{babel} % Language hyphenation and typographical rules

\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document margins
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables

\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text

\usepackage{enumitem} % Customized lists
\setlist[itemize]{noitemsep} % Make itemize lists more compact

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\usepackage{titlesec} % Allows customization of titles
\renewcommand\thesection{\Roman{section}} % Roman numerals for the sections
\renewcommand\thesubsection{\roman{subsection}} % roman numerals for subsections
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{} % Change the look of the section titles

\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
\fancyfoot{} % Blank out the default footer
\fancyhead[C]{Running title $\bullet$ May 2016 $\bullet$ Vol. XXI, No. 1} % Custom header text
\fancyfoot[RO,LE]{\thepage} % Custom footer text

\usepackage{titling} % Customizing the title section

\usepackage{hyperref} % For hyperlinks in the PDF

% RMF additions
\usepackage{graphicx}
\usepackage{amsmath}
\interfootnotelinepenalty=1000 % default is 100; discourages splitting footnotes

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\setlength{\droptitle}{-4\baselineskip} % Move the title up

\pretitle{\begin{center}\Huge\bfseries} % Article title formatting
\posttitle{\end{center}} % Article title closing formatting
\title{Emergent Behavior in Graph Automata} % Article title
\author{%
\textsc{Richard Foard}\thanks{A thank you or further information} \\[1ex] % Your name
\normalsize Georgia Tech Research Institute \\ % Your institution
\normalsize \href{mailto:richard.foard@gtri.gatech.edu}{richard.foard@gtri.gatech.edu} % Your email address
}
\date{\today} % Leave empty to omit a date
\renewcommand{\maketitlehookd}{%
\begin{abstract}
\noindent A simple, rule-based
graph automaton was defined and simulated. Each of its possible rules specifies a set
of local topology and node state changes to be applied iteratively, starting with a random initial graph.
Simulation runs were performed using many different rules, each run terminating when its graph
collapsed or cycled.
Evolving and terminal graph states were analyzed macroscopically, using
aggregate statistics, and microscopically, by inspecting graph structures.
Results were compared with those from simulations of a machine that
iterated by applying random, rather than rule-based, changes. We found that...
\end{abstract}
}

%----------------------------------------------------------------------------------------

\begin{document}

% Print the title
\maketitle

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section{Introduction}

\lettrine[nindent=0em,lines=3]{S} ince Alan Turing conceived his
universal machine in 1936, simple abstract automata have drawn research attention.
Interest broadened beyond the academic realm in 1970,
when Conway published his \textit{Game of Life} simulations [citation needed] that highlighted the ability
of uncomplicated cellular automata to behave in complex ways. Researchers in the
nascent field of complexity theory began studying similar phenomena, such as the
sandpile avalanches first explored by Per Bak (true??).

In \textit{A New Kind of Science} (199?), Stephen Wolfram methodically analyzed
a variety of cellular automata types. He found particular inspiration in the
behavior of a one-dimensional machine running "Rule 110." Among his observations were... (list
irreducibility, etc.)

Wolfram and others have also suggested that some natural processes that were
previously thought to evolve by natural selection are instead
manifestations of things that nature found "easy" to accomplish using
the same fundamental principles that underlie simple automata.

In this work, we analyze simple graph automata -- machines that operate on the same principles as
cellular automata, but use a graph, rather than a "tape" or grid, as a substrate.
Where cellular machines define cell adjacency spatially, our machines use graph topology.

%------------------------------------------------

\section{Methods}

Two similar rule-based automata, \textbf{Machine C} and \textbf{Machine CM}, were designed
and implemented in simulation. The simulators were run repeatedly, using rules
selected at random from a large universe of possibilities. Measurements were recorded as the graphs
evolved through each run. The resulting database accumulated data on many thousands of runs. The body of data
was analyzed macroscopically, using aggregate statistics, and microscopically, by inspecting
statistical and graphic snapshots from individual runs.

Each simulation run begins with a randomly generated graph and progresses by
iteratively modifying its edges and node states; changes are made according to a rule selected
for the run. Each rule is effectively a simple program  that specifies, based on the state
of each node and its two topological neighbors, how local changes should be applied during an
iteration.

\subsection{Graph Composition}

Nodes may be in one of two states: \textit{black} or \textit{white}.
Graph topology is restricted in order to simplify rule design. For the
\textbf{CM} machine:

\begin{itemize}
    \item Edges are directed.
    \item Nodes have out-degree of exactly two.
    \item "Self-linking" edges are permitted.
\end{itemize}
The \textbf{C}  machine's graphs are more narrowly defined by adding the
restriction:
\begin{itemize} 
    \item Multiple, like-directed edges between two nodes are prohibited.
\end{itemize}

\textbf{C} and \textbf{CM} machines operate using the same rule structures.
Each machine begins execution with a graph that has been randomly generated
to conform to its machine's topological restrictions. Both maintain conformance
throughout execution. In applying some rules, \textbf{C} may create prohibited
structures. When this occurs, it applies a pruning process that selectively
removes nodes and edges to restore conformance before proceeding. The \textbf{CM}
machine does not require a pruning capability because no rule can cause it to
violate its more relaxed structure restrictions. \textbf{CM} is otherwise
identical to \textbf{C}.  

An initial, random graph of size N is constructed by assigning each node
a \textit{black} or \textit{white} state with equal likelihood.
Two edges are attached to each node, with
the destination of each selected at random from all nodes. For \textbf{C} runs, the
generator observes the constraint that both edges cannot have the same destination node.
In all initial graphs, nodes have out-degree 2, but in-degree can vary from 0 to N.
Initial graphs are a subset of the class of Erdos-Renyi random graphs [citation needed]
\textit{G(n, p)} where \textit{n} is the number of nodes and \textit{p} is the probability
that two nodes are connected by an edge. Because our graphs have fixed out-degree 2,
the generation process produces randomness only in the nodes' in-degrees. As a result,
each of our initial graphs is a member of \textit{G(n, p)} where \textit{p} is a function
of graph size \textit{n} (approximately \( 4 / (n - 1) \)).

\subsection{Rule Structure and Application}

At the start of each simulation run, a rule is selected and an initial graph
is generated.  The simulation proceeds in a series of
iterations. During each, the rule is applied at each node, yielding a draft
version of a new graph. For machine \textbf{CM}, the draft immediately becomes
the input to the next iteration. In \textbf{C}, the draft may require pruning
before becoming input to the next iteration. 

The draft is then pruned to eliminate
prohibited structures, creating the input graph to the next iteration.

During an iteration, each node in the current graph is examined in turn.
The combined \textit{black}/\textit{white} states of the node and its two neighbors\footnote{In
all cases, "neighbor" is used to indicate a node at the destination end of one of a node's out-edges.}
are used to select one of the rule's eight constituent parts; the part in turn
controls the changes that are made to the node's state and its out-edges in
the developing draft copy. Rules encode change instructions as follows:

A rule comprises eight parts, each corresponding to one of the possible compound states
of a node and its neighbors. Each rule-part specifies replacement values for
the node's state and the destinations of its out-edges
(for purposes of description, it is convenient to designate a node's two out-edges "left" and "right").
The replacement node state is either \textit{black} or \textit{white}.
The replacement edge destinations are each one of:

\begin{itemize}
    \item L - the node's current left-edge destination
    \item R - the node's current right-edge destination
    \item LL - the current destination of its left neighbor's left-edge
    \item LR - the current destination of its left neighbor's right-edge
    \item RL - the current destination of its right neighbor's left-edge
    \item RR - the current destination of its right neighbor's right-edge
\end{itemize}
The process of a rule being applied to a node and its immediate neighbors is shown
schematically in (Figure \ref{fig:Fig1}).

\begin{figure*}[tb] 
    \centering
    \makebox[\textwidth]{\includegraphics[width=.9\paperwidth]{./placeholder.png}}
    \caption{A rule specifies state-dependent changes to a node's state and its out-edges.}
    \label{fig:Fig1}
\end{figure*}

After all nodes in the original graph have been processed,
the resulting draft copy is pruned if necessary.

Applicable only for machine \textbf{C}, pruning removes
any like-directed edges between pairs of nodes that have been created in the
draft copy; the process selectively removes nodes
and redirects edges, cascading as required until no prohibited structures remain.
If it is not empty, the pruned graph becomes the starting point for the next iteration;
if it is empty, it is said to have collapsed.
A simulation run ends when (1) the graph collapses, (2) a state cycle is detected,
or (3) the maximum number of iterations is reached.

\subsection{The \textbf{C*} Machines' Random Counterparts, \textbf{R} and \textbf{RM}}

To help gauge the extent to which machines \textbf{C} and \textbf{CM}
increase order as they transform random starting graphs, simulators for counterpart
machines \textbf{R} and \textbf{RM} were constructed. Like the rule-based \textbf{C*} machines,
these change graphs iteratively, but make their changes \textit{randomly}.
As with the \textbf{C*} machines, though, the scope of changes at each node is
limited to the destinations of its two out-edges. (The random machines need not alter nodes' states
because node states have no effect on the \textbf{R*} machines' actions).
The \textbf{R} machine applies the same pruning process that \textbf{C} uses. As
with \textbf{CM}, no pruning step is requied in \textbf{RM} simulations.

\subsection{The Pruning Process}

Changes to out-edge destinations, whether made randomly by machine \textbf{R} or based on \textbf{C}'s
rules, can introduce multiple, like-directed edges between nodes. These prohibited structures
arise as the machine's iteration logic creates a first-pass, "draft" copy of the transformed graph.
The draft copy is restored to conformance with structure restrictions by applying a
pruning process. In the diagram (Figure \ref{fig:Fig2}),
the two illegal configurations that require pruning are shown in red and
labeled as cases I and II.
Both are resolved by eliminating the node at which the offending edge pair
originates (labeled "A" in the illustrations), along with the edge pair.
In case I, all edges inbound to the eliminated node are redirected to 
the destination (shown as node "B") of its to-be-eliminated edge pair.
Redirected edges are shown in blue.

Lacking such a natural new destination for inbound edges in case II, the
pruning process instead moves the problem "upstream"---any edge inbound to
the eliminated node is redirected to the same destination node as that of
its origin node's other out-edge. This, of course, immediately creates
case I structure violations for all such origin nodes; these violations must also be
resolved before the pruning process is complete.
Case II resolutions \textit{always} create additional structure violations;
case I resolutions may or may not. In either case, cascades can result. These
cascades, and the resulting reductions in graph size, are common in both
\textbf{C} and \textbf{R} simulations.

\begin{figure*}[tb] 
    \centering
    %\makebox[\textwidth]{\includegraphics[width=.9\paperwidth, scale=0.7]{./pruning.png}}
    \makebox[\textwidth]{\includegraphics[scale=0.7]{./pruning.png}}
    \caption{\textbf{Pruning.} Resolution methods for two variations of a (red) prohibited structure.
In both cases, edges originating at node A are eliminated; edges in blue are redirected.
Case II creates two case I-type structures that require further resolution.}
    \label{fig:Fig2}
\end{figure*}


\subsection{The Simulator}

Input parameters and statistics gathered. Data base and analysis tooling.
Constituent packages. How parameter values were selected and varied.

%------------------------------------------------

\section{Results}

Initial graphs are finite, and each iteration
either maintains the number of nodes or, in the case of \textbf{C} and \textbf{R},
reduces it by pruning.  It is consequently certain that all machine runs will terminate,
either in a state cycle or in a graph collapse; this holds true
for \textbf{C}, \textbf{CM}, and their random counterparts.
The possibility that a graph will traverse an astronomical number
of states\footnote{The number of possible states for an N-node graph is:
\[
2^N\cdot\binom{N}{2}^N
\]
}
before revisiting a previous one, however, limits the simulator's ability to
detect cycles. If a simulator reaches a maximum number of iterations
before its machine terminates, the simulation outcome is recorded as "undetermined."
Aggregate outcome statistics for all runs appear in Table \ref{tab:Tab1}.

\begin{table}
\caption{Simulation Outcomes, All Runs}
\centering
\begin{tabular}{lrcr}
\toprule
Machine & Cycling & Collapsed & Undet. \\
\midrule
C & 40.77\% & 59.22\% & 0.01\% \\
R & 0.01\% & 99.99\% & 0\% \\
CM & 99.07\% & --- & 0.03\% \\
RM & 100.00\% & --- & 0.00\% \\
\bottomrule
\end{tabular}
\label{tab:Tab1}
\end{table}

%BOOKMARK%

Machine \textbf{C} is far less likely to produce graph collapses than
\textbf{R} is (59.3\% vs. 99.9\% of runs). In cases where \textbf{C} produces
collapses, average run length is consistently greater than
for \textbf{R} (Figure \ref{fig:figA}). For both machine types, we refer to
the number of nodes at the end of the iteration immediately preceding a collapse,
or to the "settled" number of nodes in a cycling graph, as the terminal number of nodes.

\begin{figure}
%  \fbox{\includegraphics[width=\linewidth, scale=0.6]{figA.png}}
  \includegraphics[width=\linewidth, scale=0.7]{figA.png}
  \caption{On average, the rule-based \textbf{C} machine executes more iterations than \textbf{R} before collapse occurs.}
  \label{fig:figA}
\end{figure}

\subsection{Degree and Entropy}

Machine \textbf{C}, on average, generates graphs with a larger 
maximum in-degree than in the random case (Figure \ref{fig:figC}), and also produces a
larger number of distinct in-degrees (Figure \ref{fig:figB}).

\begin{figure}
  %\fbox{\includegraphics[width=\linewidth, scale=0.7]{figC.png}}
  \includegraphics[width=\linewidth, scale=0.7]{figC.png}
  \caption{\textbf{C} produces a larger maximum in-degree than \textbf{R}.}
  \label{fig:figC}
\end{figure}

\begin{figure}
  %\fbox{\includegraphics[width=\linewidth, scale=0.7]{figB.png}}
  \includegraphics[width=\linewidth, scale=0.7]{figB.png}
  \caption{\textbf{C} produces graphs with a larger number of in-degrees.}
  \label{fig:figB}
\end{figure}

Shannon's entropy [citation needed], computed on summary in-degree statistics and
normalized\footnote{Explanation of normalization}, can be regarded a measure of
a graph's "randomness."
As would be expected, entropy is consistently large in the randomly generated
initial graphs. Between the \textbf{R} and \textbf{C} machines, entropy in the terminal
graphs for \textbf{C} is lower than that for the randomly operating R (Figure \ref{fig:figE}).
The drop in average entropy between initial graphs and the \textbf{R} machine's terminal
graphs seems surprising on its face, but is accounted for by the restriction that
\textbf{R}'s topological changes, like \textbf{C}'s, may only redirect a node's out-edge
to one of its neighbors or their neighbors.
The effect is to "localize" the randomness, increasing apparent order in the graph.

\begin{figure}
  %\fbox{\includegraphics[width=\linewidth, scale=0.7]{figE.png}}
  \includegraphics[width=\linewidth, scale=0.7]{figE.png}
  \caption{In-degree entropy is largest in initial random graphs,
        smaller for \textbf{R}'s terminal graphs, and smallest for \textbf{C}'s terminal graphs.}
  \label{fig:figE}
\end{figure}

\begin{figure}
  %\fbox{\includegraphics[width=\linewidth, scale=0.7]{figDd1024.png}}
  \includegraphics[width=\linewidth, scale=0.7]{figDd1024.png}
  \caption{\textbf{C}'s average clustering coefficients are larger than \textbf{R}'s.}
  \label{fig:figDd1024}
\end{figure}

\subsection{Cycles and Collapses}
%Unhappy Endings?

\subsection{Clustering}

Terminal clustering coefficients for machine \textbf{C} are smaller than those for \textbf{R} in
the large majority of cases (Figure \ref{fig:figDd1024}).

\subsection{Sensitivity to Initial Conditions}

This is where things get more interesting.

For this one, we'll have to dust off the old self-organizing criticality
references. Are collapses like sandpile avalanches?

\subsection{Self-Organization}
%Made to Order?

\subsection{Predictability}
%Learning the Hard Way?

\subsection{Mathematical Analysis}
%Doing the Math?

\subsection{Designed Rules}
%Designer Rules? Rules by Design?

\subsection{Interesting Configurations}
%Photo Opps?
Sorter?

\subsection{Cycles}
%In the Long Run?

\begin{table}
\caption{Example table}
\centering
\begin{tabular}{llr}
\toprule
\multicolumn{2}{c}{Name} \\
\cmidrule(r){1-2}
First name & Last Name & Grade \\
\midrule
John & Doe & $7.5$ \\
Richard & Miles & $2$ \\
\bottomrule
\end{tabular}
\end{table}

Some dummy text was here.

\begin{equation}
\label{eq:emc}
e = mc^2
\end{equation}

Some dummy text was here.

%------------------------------------------------

\section{Discussion}

Possible areas for further investigation:

\begin{itemize}
    \item Search strategies for rules with specific characteristics.
    \item Encodings of more complex graph structures.
    \item Exploring mathematical parallels.
    \item Investigating variations on the machines, both simpler and more complex.
\end{itemize}

\subsection{Subsection One}

A statement requiring citation \cite{Figueredo:2009dg}.

%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------

\begin{thebibliography}{99} % Bibliography - this is intentionally simple in this template

\bibitem[Figueredo and Wolf, 2009]{Figueredo:2009dg}
Figueredo, A.~J. and Wolf, P. S.~A. (2009).
\newblock Assortative pairing and life history strategy - a cross-cultural
  study.
\newblock {\em Human Nature}, 20:317--330.
 
\end{thebibliography}

%----------------------------------------------------------------------------------------

\end{document}
